import streamlit as st
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    RunReportRequest, DateRange, Metric, Dimension
)
from datetime import datetime
import json
import pytz
import pandas as pd

# ---------------------------------------------------------
# 0. ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ (æœ€å„ªå…ˆã§å®Ÿè¡Œ)
# ---------------------------------------------------------
st.set_page_config(page_title="Blog Analytics Pro", layout="wide")

def check_password():
    """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼æ©Ÿèƒ½"""
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    if not st.session_state.authenticated:
        st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³")
        password_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
        
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if password_input == st.secrets["auth"]["password"]:
                st.session_state.authenticated = True
                st.rerun()
            else:
                st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
        st.stop()

check_password()

# =========================================================
#  ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================================================

st.title("ğŸ“Š ãƒ–ãƒ­ã‚°åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ Pro")

# ç¾åœ¨æ™‚åˆ»
JST = pytz.timezone('Asia/Tokyo')
now = datetime.now(JST)
current_hour = now.hour

# ---------------------------------------------------------
# 1. èªè¨¼ (GCP)
# ---------------------------------------------------------
try:
    creds_json = json.loads(st.secrets["gcp_service_account"])
    client = BetaAnalyticsDataClient.from_service_account_info(creds_json)
except Exception as e:
    st.error(f"GCPèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ---------------------------------------------------------
# 2. ãƒ–ãƒ­ã‚°è¨­å®š
# ---------------------------------------------------------
BLOGS = [
    {"name": "ğŸš™ ã‚¸ãƒ ãƒ‹ãƒ¼ãƒ•ãƒªãƒ¼ã‚¯ï¼", "id": "470121869"},
    {"name": "ğŸ£ ã‚½ãƒ«ãƒˆãƒ«ã‚¢ãƒ¼ã®ã™ã™ã‚ï¼", "id": "343862616"},
    {"name": "ğŸ‘” å…¬å‹™å“¡è»¢è·ãƒãƒ³", "id": "445135719"},
]

# ---------------------------------------------------------
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
# ---------------------------------------------------------

def get_realtime_metrics(property_id):
    req_today = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="today", end_date="today")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_today = client.run_report(req_today)
    pv_today = int(res_today.rows[0].metric_values[0].value) if res_today.rows else 0

    req_yest = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="yesterday", end_date="yesterday")],
        dimensions=[Dimension(name="hour")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_yest = client.run_report(req_yest)
    
    pv_yest_same = 0
    pv_yest_total = 0
    if res_yest.rows:
        for row in res_yest.rows:
            h = int(row.dimension_values[0].value)
            pv = int(row.metric_values[0].value)
            pv_yest_total += pv
            if h <= current_hour:
                pv_yest_same += pv
                
    return pv_today, pv_yest_same, pv_yest_total

def get_top_pages_with_keywords(property_id, days):
    start_date = f"{days}daysAgo"
    
    # -------------------------------------------------
    # æˆ¦ç•¥A: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å–å¾—ã«æŒ‘æˆ¦
    # -------------------------------------------------
    try:
        request = RunReportRequest(
            property=f"properties/{property_id}",
            date_ranges=[DateRange(start_date=start_date, end_date="today")],
            dimensions=[Dimension(name="pageTitle"), Dimension(name="organicGoogleSearchQuery")],
            metrics=[Metric(name="screenPageViews")],
            limit=1000
        )
        response = client.run_report(request)
        
        raw_data = []
        if response.rows:
            for row in response.rows:
                title = row.dimension_values[0].value
                kw = row.dimension_values[1].value
                pv = int(row.metric_values[0].value)
                if title and title != "(not set)":
                    clean_kw = kw if kw and kw not in ["(not set)", "(not provided)"] else ""
                    raw_data.append({"title": title, "info": clean_kw, "pv": pv})
        
        # ãƒ‡ãƒ¼ã‚¿åŠ å·¥ã¸ï¼ˆä¸‹éƒ¨ã§å…±é€šå‡¦ç†ï¼‰
        info_label = "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰(TOP3)"
        
    # -------------------------------------------------
    # æˆ¦ç•¥B: ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰ã€Œæµå…¥å…ƒ(Source/Medium)ã€ã«åˆ‡ã‚Šæ›¿ãˆ
    # -------------------------------------------------
    except Exception:
        request_fb = RunReportRequest(
            property=f"properties/{property_id}",
            date_ranges=[DateRange(start_date=start_date, end_date="today")],
            # ã“ã“ã‚’å¤‰æ›´: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä»£ã‚ã‚Šã«ã€Œæµå…¥å…ƒã€ã‚’å–å¾—
            dimensions=[Dimension(name="pageTitle"), Dimension(name="sessionSourceMedium")],
            metrics=[Metric(name="screenPageViews")],
            limit=1000
        )
        response = client.run_report(request_fb)
        
        raw_data = []
        if response.rows:
            for row in response.rows:
                title = row.dimension_values[0].value
                source = row.dimension_values[1].value # ä¾‹: google / organic
                pv = int(row.metric_values[0].value)
                if title and title != "(not set)":
                    raw_data.append({"title": title, "info": source, "pv": pv})
        
        info_label = "ä¸»ãªæµå…¥å…ƒ(TOP3)"

    # -------------------------------------------------
    # å…±é€š: é›†è¨ˆå‡¦ç†
    # -------------------------------------------------
    df_raw = pd.DataFrame(raw_data)
    if df_raw.empty: return pd.DataFrame()

    # 1. è¨˜äº‹ã”ã¨ã®åˆè¨ˆPV
    pv_sum = df_raw.groupby("title")["pv"].sum().reset_index().sort_values("pv", ascending=False)
    
    # 2. è¨˜äº‹ã”ã¨ã®TOPæƒ…å ±ã‚’æŠ½å‡ºã—ã¦çµåˆ
    info_data = df_raw[df_raw["info"] != ""].sort_values("pv", ascending=False)
    
    def get_top_infos(title):
        # ãã®è¨˜äº‹ã®æµå…¥æƒ…å ±TOP3ã‚’å–å¾—
        infos = info_data[info_data["title"] == title]["info"].head(3).tolist()
        return ", ".join(infos) if infos else "(ä¸æ˜/Direct)"

    col_name = f"è©³ç´°: {info_label}"
    pv_sum[col_name] = pv_sum["title"].apply(get_top_infos)
    
    final_df = pv_sum.head(30).rename(columns={"title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«", "pv": "PVæ•°"})
    return final_df

# ---------------------------------------------------------
# 4. ç”»é¢è¡¨ç¤º
# ---------------------------------------------------------
st.write(f"æœ€çµ‚æ›´æ–°: {now.strftime('%Y-%m-%d %H:%M:%S')}")

tab1, tab2 = st.tabs(["â±ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ PV", "ğŸ† è¨˜äº‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°TOP30"])

with tab1:
    cols = st.columns(3)
    for i, blog in enumerate(BLOGS):
        with cols[i]:
            st.subheader(blog["name"])
            try:
                today, yest_same, yest_total = get_realtime_metrics(blog["id"])
                diff = today - yest_same
                pct = (diff / yest_same * 100) if yest_same > 0 else 0
                st.metric("ä»Šæ—¥ã®PV", f"{today:,}", f"{diff:+,} ({pct:+.1f}%)")
                st.caption(f"æ˜¨æ—¥åŒæ™‚åˆ»: {yest_same:,} / æ˜¨æ—¥è¨ˆ: {yest_total:,}")
            except Exception:
                st.error("å–å¾—ã‚¨ãƒ©ãƒ¼")

    if st.button("æ›´æ–°", key="refresh_realtime"):
        st.rerun()

with tab2:
    st.markdown("### ğŸ† äººæ°—è¨˜äº‹ TOP30")
    period_days = st.selectbox("é›†è¨ˆæœŸé–“ã‚’é¸æŠ", [7, 30], index=1, format_func=lambda x: f"éå» {x} æ—¥é–“")
    
    for blog in BLOGS:
        with st.expander(f"ğŸ“Š {blog['name']} ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°", expanded=False):
            try:
                df_top = get_top_pages_with_keywords(blog["id"], period_days)
                if not df_top.empty:
                    # ã‚°ãƒ©ãƒ•
                    st.markdown("#### ğŸ“ˆ PVæ•°æ¯”è¼ƒ")
                    chart_df = df_top.set_index("è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«")[["PVæ•°"]].sort_values("PVæ•°", ascending=True)
                    st.bar_chart(chart_df, horizontal=True, color="#FF4B4B")
                    
                    # è¡¨
                    st.markdown("#### ğŸ“ è©³ç´°ãƒ‡ãƒ¼ã‚¿")
                    st.dataframe(df_top, use_container_width=True, hide_index=True, height=500)
                else:
                    st.warning("ãƒ‡ãƒ¼ã‚¿ãªã—")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
