import streamlit as st
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    RunReportRequest, DateRange, Metric, Dimension
)
from datetime import datetime, timedelta
import json
import pytz
import pandas as pd

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="Blog Analytics", layout="wide")
st.title("ğŸ“Š ãƒ–ãƒ­ã‚°åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ç¾åœ¨æ™‚åˆ»ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
JST = pytz.timezone('Asia/Tokyo')
now = datetime.now(JST)
current_hour = now.hour

# ---------------------------------------------------------
# 1. èªè¨¼
# ---------------------------------------------------------
try:
    creds_json = json.loads(st.secrets["gcp_service_account"])
    client = BetaAnalyticsDataClient.from_service_account_info(creds_json)
except Exception as e:
    st.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: Secretsã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n{e}")
    st.stop()

# ---------------------------------------------------------
# 2. ãƒ–ãƒ­ã‚°è¨­å®š
# ---------------------------------------------------------
BLOGS = [
    {"name": "ğŸš™ ã‚¸ãƒ ãƒ‹ãƒ¼ãƒ•ãƒªãƒ¼ã‚¯ï¼", "id": "470121869"},
    {"name": "ğŸ£ ã‚½ãƒ«ãƒˆãƒ«ã‚¢ãƒ¼ã®ã™ã™ã‚ï¼", "id": "343862616"},
    {"name": "ğŸ‘” å…¬å‹™å“¡è»¢è·ãƒãƒ³", "id": "445135719"},
]

# ---------------------------------------------------------
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°ç¾¤
# ---------------------------------------------------------
def get_realtime_metrics(property_id):
    # A. ä»Šæ—¥ã®ç´¯è¨ˆ
    req_today = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="today", end_date="today")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_today = client.run_report(req_today)
    pv_today = int(res_today.rows[0].metric_values[0].value) if res_today.rows else 0

    # B. æ˜¨æ—¥ã®åŒæ™‚åˆ»ãƒ‡ãƒ¼ã‚¿
    req_yest = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="yesterday", end_date="yesterday")],
        dimensions=[Dimension(name="hour")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_yest = client.run_report(req_yest)
    
    pv_yest_same = 0
    pv_yest_total = 0
    if res_yest.rows:
        for row in res_yest.rows:
            h = int(row.dimension_values[0].value)
            pv = int(row.metric_values[0].value)
            pv_yest_total += pv
            if h <= current_hour:
                pv_yest_same += pv
                
    return pv_today, pv_yest_same, pv_yest_total

def get_search_keywords(property_id, days):
    start_date = f"{days}daysAgo"
    request = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date=start_date, end_date="today")],
        dimensions=[Dimension(name="organicGoogleSearchQuery")],
        metrics=[Metric(name="screenPageViews")],
        limit=100
    )
    response = client.run_report(request)
    
    data = []
    if response.rows:
        for row in response.rows:
            word = row.dimension_values[0].value
            pv = int(row.metric_values[0].value)
            # ãƒã‚¤ã‚ºé™¤å»
            if word and word not in ["(not set)", "(not provided)"]:
                data.append({"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": word, "PV": pv})
    
    return pd.DataFrame(data)

def get_organic_trend(property_id):
    """
    æ¤œç´¢æµå…¥ã®æ¨ç§»ã‚’å–å¾—ï¼ˆAPIå´ã§ãƒ•ã‚£ãƒ«ã‚¿ã›ãšã€Pythonå´ã§æŠ½å‡ºã™ã‚‹æ–¹å¼ã«å¤‰æ›´ï¼‰
    """
    request = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="30daysAgo", end_date="today")],
        # æ—¥ä»˜ã¨ãƒãƒ£ãƒãƒ«ï¼ˆæµå…¥å…ƒï¼‰ã‚’å–å¾—
        dimensions=[Dimension(name="date"), Dimension(name="sessionDefaultChannelGroup")],
        metrics=[Metric(name="screenPageViews")],
        order_bys=[{"dimension": {"dimension_name": "date"}}]
    )
    response = client.run_report(request)
    
    data = []
    if response.rows:
        for row in response.rows:
            date_str = row.dimension_values[0].value
            channel = row.dimension_values[1].value # æµå…¥å…ƒ
            pv = int(row.metric_values[0].value)
            
            # ã“ã“ã§ã€ŒOrganic Searchã€ã ã‘ã‚’æ‹¾ã†ï¼ˆPythonå´ã§å‡¦ç†ï¼‰
            if channel == "Organic Search":
                dt = datetime.strptime(date_str, "%Y%m%d")
                data.append({"æ—¥ä»˜": dt, "æ¤œç´¢æµå…¥PV": pv})
            
    df = pd.DataFrame(data)
    # æ—¥ä»˜ã”ã¨ã®åˆè¨ˆã‚’å†é›†è¨ˆï¼ˆå¿µã®ãŸã‚ï¼‰
    if not df.empty:
        df = df.groupby("æ—¥ä»˜").sum()
        
    return df

# ---------------------------------------------------------
# 4. ç”»é¢è¡¨ç¤º
# ---------------------------------------------------------
st.write(f"æœ€çµ‚æ›´æ–°: {now.strftime('%Y-%m-%d %H:%M:%S')}")

tab1, tab2 = st.tabs(["â±ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ PV", "ğŸ” æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰åˆ†æ"])

# --- ã‚¿ãƒ–1 ---
with tab1:
    cols = st.columns(3)
    for i, blog in enumerate(BLOGS):
        with cols[i]:
            st.subheader(blog["name"])
            try:
                today, yest_same, yest_total = get_realtime_metrics(blog["id"])
                diff = today - yest_same
                pct = (diff / yest_same * 100) if yest_same > 0 else 0
                st.metric("ä»Šæ—¥ã®PV", f"{today:,}", f"{diff:+,} ({pct:+.1f}%)")
                st.caption(f"æ˜¨æ—¥åŒæ™‚åˆ»: {yest_same:,} / æ˜¨æ—¥è¨ˆ: {yest_total:,}")
            except Exception as e:
                st.error("å–å¾—ã‚¨ãƒ©ãƒ¼")

    if st.button("æ›´æ–°", key="refresh_realtime"):
        st.rerun()

# --- ã‚¿ãƒ–2 ---
with tab2:
    st.markdown("### ğŸ” æ¤œç´¢æµå…¥ãƒ¬ãƒãƒ¼ãƒˆ")
    for blog in BLOGS:
        with st.expander(f"ğŸ“Š {blog['name']} ã®åˆ†æã‚’è¦‹ã‚‹", expanded=False):
            st.markdown("#### ğŸ“… éå»30æ—¥ã®æ¤œç´¢æµå…¥æ¨ç§»")
            try:
                trend_df = get_organic_trend(blog["id"])
                if not trend_df.empty:
                    st.line_chart(trend_df, color="#FF4B4B")
                else:
                    st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆã¾ãŸã¯æ¤œç´¢æµå…¥ã‚¼ãƒ­ï¼‰")
            except Exception as e:
                st.error(f"ã‚°ãƒ©ãƒ•å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

            st.markdown("#### ğŸ”‘ æµå…¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP100")
            col_left, col_right = st.columns(2)
            with col_left:
                st.markdown("**éå» 1é€±é–“**")
                try:
                    df_7 = get_search_keywords(blog["id"], 7)
                    if not df_7.empty:
                        st.dataframe(df_7, height=400, use_container_width=True)
                    else:
                        st.warning("ãƒ‡ãƒ¼ã‚¿ãªã—")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            with col_right:
                st.markdown("**éå» 1ãƒ¶æœˆ**")
                try:
                    df_30 = get_search_keywords(blog["id"], 30)
                    if not df_30.empty:
                        st.dataframe(df_30, height=400, use_container_width=True)
                    else:
                        st.warning("ãƒ‡ãƒ¼ã‚¿ãªã—")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
