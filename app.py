import streamlit as st
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    RunReportRequest, DateRange, Metric, Dimension
)
from datetime import datetime
import json
import pytz
import pandas as pd

# ---------------------------------------------------------
# 0. ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼
# ---------------------------------------------------------
st.set_page_config(page_title="Blog Analytics Ultimate", layout="wide")

def check_password():
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    if not st.session_state.authenticated:
        st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³")
        password_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if password_input == st.secrets["auth"]["password"]:
                st.session_state.authenticated = True
                st.rerun()
            else:
                st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
        st.stop()

check_password()

# =========================================================
#  ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================================================

st.title("ğŸ“Š ãƒ–ãƒ­ã‚°åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ Ultimate")

JST = pytz.timezone('Asia/Tokyo')
now = datetime.now(JST)
current_hour = now.hour

# ---------------------------------------------------------
# 1. èªè¨¼
# ---------------------------------------------------------
try:
    creds_json = json.loads(st.secrets["gcp_service_account"])
    client = BetaAnalyticsDataClient.from_service_account_info(creds_json)
except Exception as e:
    st.error(f"GCPèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ---------------------------------------------------------
# 2. ãƒ–ãƒ­ã‚°è¨­å®š
# ---------------------------------------------------------
BLOGS = [
    {"name": "ğŸš™ ã‚¸ãƒ ãƒ‹ãƒ¼ãƒ•ãƒªãƒ¼ã‚¯ï¼", "id": "470121869"},
    {"name": "ğŸ£ ã‚½ãƒ«ãƒˆãƒ«ã‚¢ãƒ¼ã®ã™ã™ã‚ï¼", "id": "343862616"},
    {"name": "ğŸ‘” å…¬å‹™å“¡è»¢è·ãƒãƒ³", "id": "445135719"},
]

# ---------------------------------------------------------
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
# ---------------------------------------------------------

# â‘  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ PV
def get_realtime_metrics(property_id):
    req_today = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="today", end_date="today")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_today = client.run_report(req_today)
    pv_today = int(res_today.rows[0].metric_values[0].value) if res_today.rows else 0

    req_yest = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="yesterday", end_date="yesterday")],
        dimensions=[Dimension(name="hour")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_yest = client.run_report(req_yest)
    
    pv_yest_same = 0
    pv_yest_total = 0
    if res_yest.rows:
        for row in res_yest.rows:
            h = int(row.dimension_values[0].value)
            pv = int(row.metric_values[0].value)
            pv_yest_total += pv
            if h <= current_hour:
                pv_yest_same += pv
                
    return pv_today, pv_yest_same, pv_yest_total

# â‘¡ æ—¥åˆ¥æ¨ç§»ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ (ä»ŠæœŸ vs å‰æœŸ)
def get_daily_trend_comparison(property_id, days):
    """
    ä»ŠæœŸã¨å‰æœŸã®æ—¥åˆ¥PVã‚’å–å¾—ã—ã€é‡ã­ã¦è¡¨ç¤ºã§ãã‚‹DataFrameã‚’ä½œæˆã™ã‚‹
    """
    current_start = f"{days}daysAgo"
    current_end = "today"
    prev_start = f"{days*2}daysAgo"
    prev_end = f"{days+1}daysAgo"

    # ä»ŠæœŸãƒ‡ãƒ¼ã‚¿
    req_curr = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date=current_start, end_date=current_end)],
        dimensions=[Dimension(name="date")], # æ—¥ä»˜
        metrics=[Metric(name="screenPageViews")],
        order_bys=[{"dimension": {"dimension_name": "date"}}]
    )
    res_curr = client.run_report(req_curr)
    
    # å‰æœŸãƒ‡ãƒ¼ã‚¿
    req_prev = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date=prev_start, end_date=prev_end)],
        dimensions=[Dimension(name="date")],
        metrics=[Metric(name="screenPageViews")],
        order_bys=[{"dimension": {"dimension_name": "date"}}]
    )
    res_prev = client.run_report(req_prev)

    # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆåŒ– (æ—¥ä»˜ãã®ã‚‚ã®ã§ã¯ãªãã€ŒNæ—¥ç›®ã€ã§åˆã‚ã›ã‚‹)
    curr_data = []
    if res_curr.rows:
        for row in res_curr.rows:
            curr_data.append(int(row.metric_values[0].value))

    prev_data = []
    if res_prev.rows:
        for row in res_prev.rows:
            prev_data.append(int(row.metric_values[0].value))

    # é•·ã•ã‚’æƒãˆã¦DataFrameåŒ–
    # (APIã®ä»•æ§˜ä¸Šã€ä»Šæ—¥ã‚’å«ã‚ã‚‹ã¨é•·ã•ãŒã‚ºãƒ¬ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹ç­‰ã®å‡¦ç†)
    min_len = min(len(curr_data), len(prev_data))
    if min_len == 0: return pd.DataFrame()

    df = pd.DataFrame({
        "ä»ŠæœŸã®PVæ¨ç§»": curr_data[:min_len],
        "å‰æœŸã®PVæ¨ç§»": prev_data[:min_len]
    })
    
    return df, sum(curr_data), sum(prev_data)

# â‘¢ è¨˜äº‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ¯”è¼ƒ (å·®åˆ†ï¼…å¯¾å¿œ)
def get_article_ranking_comparison(property_id, days):
    current_start = f"{days}daysAgo"
    current_end = "today"
    prev_start = f"{days*2}daysAgo"
    prev_end = f"{days+1}daysAgo"

    # --- A. ä»ŠæœŸã®ãƒ‡ãƒ¼ã‚¿ ---
    try:
        req_curr = RunReportRequest(
            property=f"properties/{property_id}",
            date_ranges=[DateRange(start_date=current_start, end_date=current_end)],
            dimensions=[Dimension(name="pageTitle"), Dimension(name="organicGoogleSearchQuery")],
            metrics=[Metric(name="screenPageViews")],
            limit=1000
        )
        res_curr = client.run_report(req_curr)
        raw_data = []
        is_keyword = True
        if res_curr.rows:
            for row in res_curr.rows:
                title = row.dimension_values[0].value
                info = row.dimension_values[1].value
                pv = int(row.metric_values[0].value)
                if title and title != "(not set)":
                    clean = info if info and info not in ["(not set)", "(not provided)"] else ""
                    raw_data.append({"title": title, "info": clean, "pv": pv})

    except Exception:
        is_keyword = False
        req_fb = RunReportRequest(
            property=f"properties/{property_id}",
            date_ranges=[DateRange(start_date=current_start, end_date=current_end)],
            dimensions=[Dimension(name="pageTitle"), Dimension(name="sessionSourceMedium")],
            metrics=[Metric(name="screenPageViews")],
            limit=1000
        )
        res_fb = client.run_report(req_fb)
        raw_data = []
        if res_fb.rows:
            for row in res_fb.rows:
                title = row.dimension_values[0].value
                info = row.dimension_values[1].value
                pv = int(row.metric_values[0].value)
                if title and title != "(not set)":
                    raw_data.append({"title": title, "info": info, "pv": pv})

    df_curr = pd.DataFrame(raw_data)
    if df_curr.empty: return pd.DataFrame()

    df_curr_grouped = df_curr.groupby("title")["pv"].sum().reset_index().rename(columns={"pv": "ä»ŠæœŸã®PV"})
    
    info_data = df_curr[df_curr["info"] != ""].sort_values("pv", ascending=False)
    def get_top_infos(title):
        infos = info_data[info_data["title"] == title]["info"].head(3).tolist()
        return ", ".join(infos) if infos else "-"
    
    col_info = "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰(TOP3)" if is_keyword else "ä¸»ãªæµå…¥å…ƒ(TOP3)"
    df_curr_grouped[col_info] = df_curr_grouped["title"].apply(get_top_infos)

    # --- B. å‰æœŸã®ãƒ‡ãƒ¼ã‚¿ ---
    req_prev = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date=prev_start, end_date=prev_end)],
        dimensions=[Dimension(name="pageTitle")],
        metrics=[Metric(name="screenPageViews")],
        limit=2000
    )
    res_prev = client.run_report(req_prev)
    prev_data = []
    if res_prev.rows:
        for row in res_prev.rows:
            prev_data.append({
                "title": row.dimension_values[0].value,
                "å‰æœŸã®PV": int(row.metric_values[0].value)
            })
    
    df_prev = pd.DataFrame(prev_data)
    
    # --- C. çµåˆã¨è¨ˆç®— ---
    merged = pd.merge(df_curr_grouped, df_prev, on="title", how="left")
    merged["å‰æœŸã®PV"] = merged["å‰æœŸã®PV"].fillna(0).astype(int)
    
    # å·®åˆ†ã¨ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è¨ˆç®—
    merged["å·®åˆ†"] = merged["ä»ŠæœŸã®PV"] - merged["å‰æœŸã®PV"]
    
    def calc_pct(row):
        if row["å‰æœŸã®PV"] > 0:
            return f"{(row['å·®åˆ†'] / row['å‰æœŸã®PV'] * 100):+.1f}%"
        elif row["ä»ŠæœŸã®PV"] > 0:
            return "NEW" # å‰æœŸ0ã§ä»ŠæœŸã‚ã‚Šã®å ´åˆ
        else:
            return "0%"

    merged["å‰æœŸé–“æ¯”"] = merged.apply(calc_pct, axis=1)

    # ã‚½ãƒ¼ãƒˆã¨åˆ—æ•´ç†
    final = merged.sort_values("ä»ŠæœŸã®PV", ascending=False).head(30)
    final = final[["title", "ä»ŠæœŸã®PV", "å‰æœŸã®PV", "å‰æœŸé–“æ¯”", col_info]]
    final = final.rename(columns={"title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«"})
    
    return final

# ---------------------------------------------------------
# 4. ç”»é¢è¡¨ç¤º
# ---------------------------------------------------------
st.write(f"æœ€çµ‚æ›´æ–°: {now.strftime('%Y-%m-%d %H:%M:%S')}")

tab1, tab2 = st.tabs(["â±ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ PV", "ğŸ“ˆ æœŸé–“åˆ†æãƒ¬ãƒãƒ¼ãƒˆ"])

# --- ã‚¿ãƒ–1 ---
with tab1:
    cols = st.columns(3)
    for i, blog in enumerate(BLOGS):
        with cols[i]:
            st.subheader(blog["name"])
            try:
                today, yest_same, yest_total = get_realtime_metrics(blog["id"])
                diff = today - yest_same
                pct = (diff / yest_same * 100) if yest_same > 0 else 0
                st.metric("ä»Šæ—¥ã®PV", f"{today:,}", f"{diff:+,} ({pct:+.1f}%)")
                st.caption(f"æ˜¨æ—¥åŒæ™‚åˆ»: {yest_same:,} / æ˜¨æ—¥è¨ˆ: {yest_total:,}")
            except Exception:
                st.error("å–å¾—ã‚¨ãƒ©ãƒ¼")
    if st.button("æ›´æ–°", key="refresh_realtime"):
        st.rerun()

# --- ã‚¿ãƒ–2 ---
with tab2:
    st.markdown("### ğŸ“ˆ æœŸé–“æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
    
    col_sel, _ = st.columns([1, 2])
    with col_sel:
        period_days = st.selectbox(
            "åˆ†ææœŸé–“", [7, 30], index=1, 
            format_func=lambda x: f"éå» {x} æ—¥é–“ vs ãã®å‰ã® {x} æ—¥é–“"
        )
    
    for blog in BLOGS:
        with st.expander(f"ğŸ“Š {blog['name']} ã®è©³ç´°åˆ†æ", expanded=True):
            try:
                # 1. æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ• (æ—¥åˆ¥æ¨ç§»æ¯”è¼ƒ)
                df_trend, curr_sum, prev_sum = get_daily_trend_comparison(blog["id"], period_days)
                
                # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
                diff_total = curr_sum - prev_sum
                pct_total = (diff_total / prev_sum * 100) if prev_sum > 0 else 0
                
                st.markdown(f"#### ğŸ“… ç·PV: {curr_sum:,} ({pct_total:+.1f}%)")
                
                if not df_trend.empty:
                    # æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
                    st.line_chart(df_trend, color=["#FF4B4B", "#CCCCCC"]) 
                    # â€»èµ¤è‰²ãŒä»ŠæœŸã€ã‚°ãƒ¬ãƒ¼ãŒå‰æœŸã«ãªã‚‹ã‚ˆã†ã«è¨­å®š
                    st.caption("èµ¤ç·š: ä»ŠæœŸã®æ¨ç§» / ã‚°ãƒ¬ãƒ¼ç·š: å‰æœŸã®æ¨ç§»")

                # 2. ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨
                df_top = get_article_ranking_comparison(blog["id"], period_days)
                
                if not df_top.empty:
                    st.markdown("#### ğŸ† è¨˜äº‹åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚° TOP30")
                    st.dataframe(
                        df_top, 
                        use_container_width=True, 
                        hide_index=True,
                        height=600
                    )
                else:
                    st.warning("ãƒ‡ãƒ¼ã‚¿ãªã—")
                    
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
