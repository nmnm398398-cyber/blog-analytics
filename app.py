import streamlit as st
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    RunReportRequest, DateRange, Metric, Dimension
)
from datetime import datetime, timedelta
import json
import pytz
import pandas as pd

# ---------------------------------------------------------
# è¨­å®šã‚¨ãƒªã‚¢
# ---------------------------------------------------------
st.set_page_config(page_title="Blog Analytics Pro", layout="wide")
st.title("ğŸ“Š ãƒ–ãƒ­ã‚°åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ Pro")

# ç¾åœ¨æ™‚åˆ»
JST = pytz.timezone('Asia/Tokyo')
now = datetime.now(JST)
current_hour = now.hour

# ---------------------------------------------------------
# 1. èªè¨¼
# ---------------------------------------------------------
try:
    creds_json = json.loads(st.secrets["gcp_service_account"])
    client = BetaAnalyticsDataClient.from_service_account_info(creds_json)
except Exception as e:
    st.error(f"èªè¨¼ã‚¨ãƒ©ãƒ¼: Secretsã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n{e}")
    st.stop()

# ---------------------------------------------------------
# 2. ãƒ–ãƒ­ã‚°è¨­å®š
# ---------------------------------------------------------
BLOGS = [
    {"name": "ğŸš™ ã‚¸ãƒ ãƒ‹ãƒ¼ãƒ•ãƒªãƒ¼ã‚¯ï¼", "id": "470121869"},
    {"name": "ğŸ£ ã‚½ãƒ«ãƒˆãƒ«ã‚¢ãƒ¼ã®ã™ã™ã‚ï¼", "id": "343862616"},
    {"name": "ğŸ‘” å…¬å‹™å“¡è»¢è·ãƒãƒ³", "id": "445135719"},
]

# ---------------------------------------------------------
# 3. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
# ---------------------------------------------------------

# â‘  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ PV
def get_realtime_metrics(property_id):
    # ä»Šæ—¥ã®ç´¯è¨ˆ
    req_today = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="today", end_date="today")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_today = client.run_report(req_today)
    pv_today = int(res_today.rows[0].metric_values[0].value) if res_today.rows else 0

    # æ˜¨æ—¥ã®åŒæ™‚åˆ»
    req_yest = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="yesterday", end_date="yesterday")],
        dimensions=[Dimension(name="hour")],
        metrics=[Metric(name="screenPageViews")],
    )
    res_yest = client.run_report(req_yest)
    
    pv_yest_same = 0
    pv_yest_total = 0
    if res_yest.rows:
        for row in res_yest.rows:
            h = int(row.dimension_values[0].value)
            pv = int(row.metric_values[0].value)
            pv_yest_total += pv
            if h <= current_hour:
                pv_yest_same += pv
                
    return pv_today, pv_yest_same, pv_yest_total

# â‘¡ æ¤œç´¢æµå…¥ãƒˆãƒ¬ãƒ³ãƒ‰
def get_organic_trend(property_id):
    request = RunReportRequest(
        property=f"properties/{property_id}",
        date_ranges=[DateRange(start_date="30daysAgo", end_date="today")],
        dimensions=[Dimension(name="date"), Dimension(name="sessionDefaultChannelGroup")],
        metrics=[Metric(name="screenPageViews")],
        order_bys=[{"dimension": {"dimension_name": "date"}}]
    )
    response = client.run_report(request)
    
    data = []
    if response.rows:
        for row in response.rows:
            date_str = row.dimension_values[0].value
            channel = row.dimension_values[1].value
            pv = int(row.metric_values[0].value)
            if channel == "Organic Search":
                dt = datetime.strptime(date_str, "%Y%m%d")
                data.append({"æ—¥ä»˜": dt, "æ¤œç´¢æµå…¥PV": pv})
            
    df = pd.DataFrame(data)
    if not df.empty:
        df = df.groupby("æ—¥ä»˜").sum()
    return df

# â‘¢ TOP30è¨˜äº‹ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚¨ãƒ©ãƒ¼è‡ªå‹•å›é¿æ©Ÿèƒ½ä»˜ãï¼‰
def get_top_pages_with_keywords(property_id, days):
    start_date = f"{days}daysAgo"
    
    # --- ãƒˆãƒ©ã‚¤1: è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ« ï¼‹ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ã‚’åŒæ™‚ã«å–å¾— ---
    try:
        request = RunReportRequest(
            property=f"properties/{property_id}",
            date_ranges=[DateRange(start_date=start_date, end_date="today")],
            # ã‚¿ã‚¤ãƒˆãƒ«ã¨æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ã‚»ãƒƒãƒˆã§è¦æ±‚
            dimensions=[Dimension(name="pageTitle"), Dimension(name="organicGoogleSearchQuery")],
            metrics=[Metric(name="screenPageViews")],
            limit=1000 # é›†è¨ˆå‰ãªã®ã§å¤šã‚ã«å–å¾—
        )
        response = client.run_report(request)
        
        raw_data = []
        if response.rows:
            for row in response.rows:
                title = row.dimension_values[0].value
                kw = row.dimension_values[1].value
                pv = int(row.metric_values[0].value)
                
                # ã‚´ãƒŸãƒ‡ãƒ¼ã‚¿ã®é™¤å»
                if title and title != "(not set)":
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã¯ã€Œ-ã€ã«ã™ã‚‹
                    clean_kw = kw if kw and kw not in ["(not set)", "(not provided)"] else ""
                    raw_data.append({"title": title, "kw": clean_kw, "pv": pv})
        
        df_raw = pd.DataFrame(raw_data)
        
        if df_raw.empty:
            return pd.DataFrame()

        # --- é›†è¨ˆå‡¦ç†: è¨˜äº‹ã”ã¨ã«PVã‚’åˆè¨ˆã—ã€ä¸»ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º ---
        # 1. è¨˜äº‹ã”ã¨ã®åˆè¨ˆPVã‚’è¨ˆç®—
        pv_sum = df_raw.groupby("title")["pv"].sum().reset_index().sort_values("pv", ascending=False)
        
        # 2. è¨˜äº‹ã”ã¨ã®ã€Œå¤šã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ãƒˆãƒƒãƒ—3ã‚’æŠ½å‡ºã—ã¦æ–‡å­—åˆ—çµåˆ
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹è¡Œã ã‘ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œã‚‹
        kw_data = df_raw[df_raw["kw"] != ""].sort_values("pv", ascending=False)
        
        # å„è¨˜äº‹ã®ãƒˆãƒƒãƒ—3ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦çµåˆã™ã‚‹é–¢æ•°
        def get_top_kws(title):
            kws = kw_data[kw_data["title"] == title]["kw"].head(3).tolist()
            return ", ".join(kws) if kws else "ãƒ‡ãƒ¼ã‚¿ãªã—"

        pv_sum["æµå…¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰(TOP3)"] = pv_sum["title"].apply(get_top_kws)
        
        # ä¸Šä½30è¨˜äº‹ã«çµã‚‹
        final_df = pv_sum.head(30)
        final_df = final_df.rename(columns={"title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«", "pv": "PVæ•°"})
        
        return final_df

    # --- ãƒˆãƒ©ã‚¤2: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰ã€Œã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ã€ã§å†å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ---
    except Exception:
        # 400ã‚¨ãƒ©ãƒ¼ãªã©ãŒå‡ºãŸå ´åˆã€å®‰å…¨ç­–ã¨ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã ã‘ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œã‚‹
        request_fallback = RunReportRequest(
            property=f"properties/{property_id}",
            date_ranges=[DateRange(start_date=start_date, end_date="today")],
            dimensions=[Dimension(name="pageTitle")],
            metrics=[Metric(name="screenPageViews")],
            limit=30
        )
        resp_fallback = client.run_report(request_fallback)
        
        data_fb = []
        if resp_fallback.rows:
            for row in resp_fallback.rows:
                title = row.dimension_values[0].value
                pv = int(row.metric_values[0].value)
                if title and title != "(not set)":
                    data_fb.append({"è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«": title, "PVæ•°": pv, "æµå…¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰(TOP3)": "å–å¾—ä¸å¯(é€£æºæœªè¨­å®š)"})
        
        return pd.DataFrame(data_fb)

# ---------------------------------------------------------
# 4. ç”»é¢è¡¨ç¤º
# ---------------------------------------------------------
st.write(f"æœ€çµ‚æ›´æ–°: {now.strftime('%Y-%m-%d %H:%M:%S')}")

tab1, tab2 = st.tabs(["â±ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ PV", "ğŸ† è¨˜äº‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°TOP30"])

# --- ã‚¿ãƒ–1: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ---
with tab1:
    cols = st.columns(3)
    for i, blog in enumerate(BLOGS):
        with cols[i]:
            st.subheader(blog["name"])
            try:
                today, yest_same, yest_total = get_realtime_metrics(blog["id"])
                diff = today - yest_same
                pct = (diff / yest_same * 100) if yest_same > 0 else 0
                st.metric("ä»Šæ—¥ã®PV", f"{today:,}", f"{diff:+,} ({pct:+.1f}%)")
                st.caption(f"æ˜¨æ—¥åŒæ™‚åˆ»: {yest_same:,} / æ˜¨æ—¥è¨ˆ: {yest_total:,}")
            except Exception:
                st.error("å–å¾—ã‚¨ãƒ©ãƒ¼")

    if st.button("æ›´æ–°", key="refresh_realtime"):
        st.rerun()

# --- ã‚¿ãƒ–2: è¨˜äº‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°TOP30 ---
with tab2:
    st.markdown("### ğŸ† äººæ°—è¨˜äº‹ TOP30 & æµå…¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
    
    # æœŸé–“é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30æ—¥ï¼‰
    period_days = st.selectbox("é›†è¨ˆæœŸé–“ã‚’é¸æŠ", [7, 30], index=1, format_func=lambda x: f"éå» {x} æ—¥é–“")
    
    for blog in BLOGS:
        with st.expander(f"ğŸ“Š {blog['name']} ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¦‹ã‚‹", expanded=False):
            try:
                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                df_top = get_top_pages_with_keywords(blog["id"], period_days)
                
                if not df_top.empty:
                    # 1. æ£’ã‚°ãƒ©ãƒ•è¡¨ç¤º (PVæ•°)
                    st.markdown("#### ğŸ“ˆ PVæ•°æ¯”è¼ƒ (TOP30)")
                    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã—ã¦ã‚°ãƒ©ãƒ•åŒ–
                    chart_df = df_top.set_index("è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«")[["PVæ•°"]].sort_values("PVæ•°", ascending=True)
                    st.bar_chart(chart_df, horizontal=True, color="#FF4B4B")
                    
                    # 2. è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä»˜ã)
                    st.markdown("#### ğŸ“ è©³ç´°ãƒ‡ãƒ¼ã‚¿")
                    st.dataframe(
                        df_top[["è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«", "PVæ•°", "æµå…¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰(TOP3)"]], 
                        use_container_width=True, 
                        hide_index=True,
                        height=500
                    )
                else:
                    st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                    
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
